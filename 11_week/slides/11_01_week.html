<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Associations Among Quantitative Variables</title>
    <meta charset="utf-8" />
    <meta name="author" content="Jared Edgerton" />
    <script src="11_01_week_files/header-attrs-2.29/header-attrs.js"></script>
    <link href="11_01_week_files/remark-css-0.0.1/default.css" rel="stylesheet" />
    <link href="11_01_week_files/remark-css-0.0.1/metropolis.css" rel="stylesheet" />
    <link href="11_01_week_files/remark-css-0.0.1/metropolis-fonts.css" rel="stylesheet" />
    <link rel="stylesheet" href="plsc498.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

.title[
# Associations Among Quantitative Variables
]
.subtitle[
## Scatterplots, correlation, and multivariate structure
]
.author[
### Jared Edgerton
]

---



# Quiz on canvas

- Log on to the course website to take it.
- You have 10 minutes.
- It is open notes and web.
- Do not generate your answers with AI.

---

# Quick Recap

- Last time, we focused on **composition**:
  - parts-to-whole reasoning (denominators)
  - stacked vs side-by-side comparisons
  - nested proportions (conditioning with facets)

Today, we focus on **associations among quantitative variables**:

- scatterplots and paired data
- correlation intuition (Pearson vs rank-based)
- correlograms (many variables at once)
- avoiding overclaiming
- (brief) dimension reduction as projection + information loss

---

# Simulated data for today



``` r
library(ggplot2); library(dplyr); library(tidyr); library(forcats); library(scales)
set.seed(123)
df &lt;- tibble(
  id = 1:1800,
  context = sample(
    c("Urban", "Suburban", "Rural"),
    size = 1800,
    replace = TRUE,
    prob = c(0.45, 0.35, 0.20)
  ),
  age = round(rnorm(1800, mean = 40, sd = 12))
) %&gt;%  mutate(
    context = factor(context, levels = c("Urban", "Suburban", "Rural")),
    age = pmin(pmax(age, 18), 75),
    news = rbeta(1800, 2, 2) * 10 +
      case_when(context == "Urban" ~ 0.8, context == "Rural" ~ -0.7, TRUE ~ 0) + rnorm(1800, 0, 0.6),
    news = pmin(pmax(news, 0), 10)
  )
```

---

# Simulated data outcomes


``` r
df &lt;- df %&gt;%
  mutate(
    knowledge = 40 + 4.2 * news + 0.35 * (age - 40) + rnorm(1800, 0, 8),
    knowledge = pmin(pmax(knowledge, 0), 100),
    trust = 4.4 + 0.02 * knowledge - 0.10 * news +
      case_when(context == "Rural" ~ 0.2, TRUE ~ 0) +
      rnorm(1800, 0, 0.6),
    trust = pmin(pmax(trust, 1), 7),
    support = 50 + 0.55 * knowledge - 0.40 * (age - 40) +
      case_when(context == "Rural" ~ -4, TRUE ~ 0) +
      rnorm(1800, 0, 10),
    support = pmin(pmax(support, 0), 100)
  )
```

---

# Simulated data tails


``` r
df &lt;- df %&gt;%
  mutate(
    donation = exp(news / 2) * 15 + rlnorm(1800, meanlog = 0, sdlog = 0.25),
    log_donation = log(donation),
    polarization = 12 + 2.2 * (news - 5)^2 + rnorm(1800, 0, 1.8),
    polarization = pmin(pmax(polarization, 0), 45),
    trust_t1 = pmin(pmax(trust + rnorm(1800, 0, 0.4), 1), 7),
    trust_t2 = pmin(pmax(
      trust_t1 +
        0.25 * (context == "Urban") - 0.20 * (context == "Rural") +
        rnorm(1800, 0, 0.35),
      1
    ), 7)
  ) %&gt;%
  select(id, context, age, news, knowledge, trust, support, donation, log_donation,
         polarization, trust_t1, trust_t2)
```

---

# Inspect data


``` r
df %&gt;% 
  slice(1:10)
```

```
## # A tibble: 10 × 12
##       id context    age  news knowledge trust support donation log_donation
##    &lt;int&gt; &lt;fct&gt;    &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;        &lt;dbl&gt;
##  1     1 Urban       28 0.320      45.5  5.22    70.1     18.9         2.94
##  2     2 Suburban    31 4.29       59.6  5.50    95.8    129.          4.86
##  3     3 Urban       44 2.12       42.3  4.10    65.8     43.9         3.78
##  4     4 Rural       60 3.47       59.6  5.87    60.5     86.0         4.45
##  5     5 Rural       53 0.814      47.6  5.08    63.3     23.6         3.16
##  6     6 Urban       33 6.70       66.9  4.80    82.0    428.          6.06
##  7     7 Suburban    50 6.59       80.1  5.50   100      406.          6.01
##  8     8 Rural       39 3.19       41.7  5.41    62.9     75.2         4.32
##  9     9 Suburban    44 2.85       42.5  4.67    95.5     63.2         4.15
## 10    10 Suburban    43 3.65       55.9  4.53    77.9     93.6         4.54
## # ℹ 3 more variables: polarization &lt;dbl&gt;, trust_t1 &lt;dbl&gt;, trust_t2 &lt;dbl&gt;
```

---

# Scatterplots are arguments

A scatterplot is not a decoration. It's a claim about a relationship.

Before you plot, decide what you're trying to argue:

- **Direction:** do higher x values tend to come with higher y values?
- **Strength:** is the pattern consistent or noisy?
- **Form:** linear, curved, clustered, threshold-y?
- **Exceptions:** outliers, subgroups, different regimes?

Also: distinguish **mapping** vs **styling**.

- **Mapping:** `aes(color = context)` (data → appearance)
- **Styling:** `color = "black"` (fixed choice)

---

# Example: a basic scatterplot

We start with position (x and y). Add transparency to reduce overplotting.


``` r
ggplot(df, aes(x = news, y = knowledge)) +
  geom_point(alpha = 0.25, size = 1) +
  theme_classic() +
  labs(x = "News use (0–10)", y = "Political knowledge (0–100)",title = "News use and knowledge", subtitle = "Each point is one respondent") 
```

![](11_01_week_files/figure-html/unnamed-chunk-5-1.png)&lt;!-- --&gt;

---

# Interpretation: what can we say?

This plot supports a cautious claim:

- People who report more news use **tend** to score higher on knowledge.
- The relationship is not perfect: there's substantial spread at each x value.

Common overclaims to avoid:

- “News use causes knowledge.”
- “This is a strong relationship.” (How do you know it's strong?)
- “Everyone behaves like the trend line.”

---

# Example: mapping a third variable (color)

Color can help you see subgroup structure—*if* it reveals separation.


``` r
ggplot(df, aes(x = news, y = knowledge, color = context)) +
  geom_point(alpha = 0.30, size = 1) +
  theme_classic() +
  theme(legend.position = "bottom") +
  labs(x = "News use (0–10)", y = "Political knowledge (0–100)", color = NULL, title = "Adding context as a mapping", subtitle = "Same x and y, but now we can see group structure")
```

![](11_01_week_files/figure-html/unnamed-chunk-6-1.png)&lt;!-- --&gt;

---

# Pause and discuss with a neighbor

Look at the colored scatterplot.

**Prompt:**

- What does color make easier to see?
- What does it make harder to see?
- If you removed the legend, could you still interpret it?

---

# Example: small multiples (facets)

When color gets crowded, small multiples often win.


``` r
ggplot(df, aes(x = news, y = knowledge)) +
  geom_point(alpha = 0.25, size = 1) +
  facet_wrap(~ context, nrow = 1) +
  theme_classic() +
  labs(x = "News use (0–10)",y = "Political knowledge (0–100)", title = "Conditioning on context", subtitle = "Facets separate patterns without relying on a legend")
```

![](11_01_week_files/figure-html/unnamed-chunk-7-1.png)&lt;!-- --&gt;

---

# Smoothers: useful summaries 

A smoother is a *layer* that makes an implicit model choice.

Why it can help:

- shows the average pattern when points are noisy
- highlights curvature you might miss

Why it can mislead:

- can look more “certain” than the data justify
- different smoothers tell different stories

---

# Example: scatterplot + smoother


``` r
ggplot(df, aes(x = knowledge, y = support)) +
  geom_point(alpha = 0.18, size = 1) +
  geom_smooth(se = FALSE) +
  theme_classic() +
  labs(x = "Political knowledge (0–100)", y = "Policy support (0–100)", title = "Support vs knowledge (with smoother)", subtitle = "Treat the smoother as a summary, not a mechanism")
```

![](11_01_week_files/figure-html/unnamed-chunk-8-1.png)&lt;!-- --&gt;

---

# Correlation intuition (two flavors)

Correlation is a *summary statistic* for how tightly points fall around a pattern.

Two common choices:

- **Pearson correlation:** measures *linear* association  
- **Rank-based correlation (Spearman):** measures *monotonic* association (based on ranks)

Interpretation habit:

- Use correlation to **support** what you already see in the scatterplot.
- Don't use correlation to replace the scatterplot.

---

# Example: one outlier can dominate


``` r
set.seed(999)
demo &lt;- tibble(x = rnorm(120, 0, 1), y = x + rnorm(120, 0, 0.6))
demo_with_outlier &lt;- demo %&gt;%
  bind_rows(tibble(x = 6, y = -6))
demo_plot &lt;- bind_rows(demo %&gt;% mutate(version = "No outlier"),
  demo_with_outlier %&gt;% mutate(version = "With one outlier"))
ggplot(demo_plot, aes(x = x, y = y)) +
  geom_point(alpha = 0.8, size = 1.4) +
  facet_wrap(~ version, nrow = 1) +
  theme_classic() +
  labs(x = "x", y = "y", title = "Same pattern, different correlation story")
```

![](11_01_week_files/figure-html/unnamed-chunk-9-1.png)&lt;!-- --&gt;

---

# What changed? (Pearson vs rank-based)


``` r
pearson_no &lt;- cor(demo$x, demo$y, method = "pearson")
spearman_no &lt;- cor(demo$x, demo$y, method = "spearman")
pearson_out &lt;- cor(demo_with_outlier$x, demo_with_outlier$y, method = "pearson")
spearman_out &lt;- cor(demo_with_outlier$x, demo_with_outlier$y, method = "spearman")
tibble(version = c("No outlier", "With one outlier"),
  pearson = c(pearson_no, pearson_out),
  spearman = c(spearman_no, spearman_out)
) %&gt;%
  mutate(across(c(pearson, spearman), ~ round(.x, 2)))
```

```
## # A tibble: 2 × 3
##   version          pearson spearman
##   &lt;chr&gt;              &lt;dbl&gt;    &lt;dbl&gt;
## 1 No outlier          0.88     0.88
## 2 With one outlier    0.49     0.84
```

---

# Example: monotonic but nonlinear

This relationship is clearly increasing, but it curves.


``` r
ggplot(df, aes(x = news, y = donation)) +
  geom_point(alpha = 0.18, size = 1) +
  theme_classic() +
  labs(x = "News use (0–10)", y = "Donations (simulated units)", title = "Monotonic but nonlinear", subtitle = "Pearson (linear) and Spearman (rank-based) summarize different things")
```

![](11_01_week_files/figure-html/unnamed-chunk-11-1.png)&lt;!-- --&gt;

---

# Correlation numbers (and what they mean)


``` r
tibble(
  pearson = cor(df$news, df$donation, method = "pearson"),
  spearman = cor(df$news, df$donation, method = "spearman")
) %&gt;%
  mutate(across(everything(), ~ round(.x, 2)))
```

```
## # A tibble: 1 × 2
##   pearson spearman
##     &lt;dbl&gt;    &lt;dbl&gt;
## 1    0.84        1
```

---

# Correlation can miss real structure

If the relationship is *non-monotonic*, both correlations can be near zero.


``` r
ggplot(df, aes(x = news, y = polarization)) +
  geom_point(alpha = 0.18, size = 1) +
  theme_classic() +
  labs(x = "News use (0–10)", y = "Polarization (0–45)", title = "A strong pattern with low correlation", subtitle = "The structure is real, but correlation is the wrong summary")
```

![](11_01_week_files/figure-html/unnamed-chunk-13-1.png)&lt;!-- --&gt;

---

# Data visualization critique

- Take five minutes
  - What relationship is the figure claiming?
  - Is the main comparison happening by **position** or by something less accurate?
  - Does the design help you assess *strength* vs *noise*?
  - What is one concrete improvement?

.center[
&lt;img src="vientam_weather.png" style="width:70%;"&gt;
]

---

# Many variables: correlograms

When you have several quantitative variables, you often need:

- a *quick summary* of pairwise relationships
- a way to spot clusters (variables that move together)
- a place to decide what to explore next with scatterplots

A correlogram is a map of correlations.

---

# Example: correlation heatmap (Pearson)


``` r
cor_vars &lt;- df %&gt;%
  select(age, news, knowledge, trust, support, polarization, log_donation)
cor_mat &lt;- cor(cor_vars, method = "pearson")
cor_df &lt;- as.data.frame(cor_mat) %&gt;%
  tibble::rownames_to_column(var = "var1") %&gt;%
  pivot_longer(-var1, names_to = "var2", values_to = "r") %&gt;%
  mutate(
    var1 = factor(var1, levels = colnames(cor_mat)),
    var2 = factor(var2, levels = colnames(cor_mat))
  )
```

![](11_01_week_files/figure-html/unnamed-chunk-15-1.png)&lt;!-- --&gt;

---

# Example: correlation heatmap (rank)

Rank-based correlation is often a better default when: (a) the relationship is monotonic but curved, (b) the data have outliers, and (c) you're using ordinal-ish measures.


``` r
cor_mat_s &lt;- cor(cor_vars, method = "spearman")
cor_df_s &lt;- as.data.frame(cor_mat_s) %&gt;%
  tibble::rownames_to_column(var = "var1") %&gt;%
  pivot_longer(-var1, names_to = "var2", values_to = "r") %&gt;%
  mutate(
    var1 = factor(var1, levels = colnames(cor_mat_s)),
    var2 = factor(var2, levels = colnames(cor_mat_s)))
```

![](11_01_week_files/figure-html/unnamed-chunk-17-1.png)&lt;!-- --&gt;

---

# Paired data: the same units twice

Paired data are repeated measurements on the same people/units.

Questions paired plots help answer:

- Who changed the most?
- Did most change in the same direction?
- Are there stable “high” and “low” units?

---

# Example: paired scatterplot + identity line


``` r
ggplot(df, aes(x = trust_t1, y = trust_t2)) +
  geom_abline(slope = 1, intercept = 0, linewidth = 0.8, alpha = 0.5) +
  geom_point(alpha = 0.25, size = 1) +
  coord_equal(xlim = c(1, 7), ylim = c(1, 7)) +
  theme_classic() +
  labs(x = "Trust (time 1)", y = "Trust (time 2)", title = "Paired measurements", subtitle = "Points above the line increased; below the line decreased")
```

![](11_01_week_files/figure-html/unnamed-chunk-18-1.png)&lt;!-- --&gt;

---

# Example: a slopegraph view (sampled)


``` r
set.seed(202)
ids_small &lt;- df %&gt;% sample_n(40) %&gt;% pull(id)
df_long &lt;- df %&gt;%
  filter(id %in% ids_small) %&gt;%
  select(id, context, trust_t1, trust_t2) %&gt;%
  pivot_longer(cols = c(trust_t1, trust_t2), names_to = "time", values_to = "trust") %&gt;%
  mutate(time = recode(time, trust_t1 = "Time 1", trust_t2 = "Time 2"), 
         time = factor(time, levels = c("Time 1", "Time 2")))
```

![](11_01_week_files/figure-html/unnamed-chunk-20-1.png)&lt;!-- --&gt;

---

# Data visualization critique

- Take five minutes
  - What is the “unit” of analysis (a person, a country, a school)?
  - Is the plot showing *paired* change or cross-sectional association?
  - Are you tempted to interpret it causally? Why?
  - What would a better comparison look like?

.center[
&lt;img src="investment_rank.png" style="width:60%;"&gt;
]

---

# Dimension reduction (intuition only)

When you have lots of correlated variables:

- many columns overlap in the information they contain
- plots get cluttered quickly
- summaries like correlograms help, but they’re still pairwise

A dimension reduction technique creates **new axes** that are:

- combinations of the original variables
- designed to capture “as much information as possible” in fewer dimensions

Think: **projection + information loss**.

---

# Optional: PCA as a geometric summary


``` r
pca_df &lt;- df %&gt;%
  select(age, news, knowledge, trust, support, polarization, log_donation) %&gt;%
  mutate(across(everything(), as.numeric))

pca_fit &lt;- prcomp(pca_df, center = TRUE, scale. = TRUE)

pca_scores &lt;- as_tibble(pca_fit$x[, 1:2]) %&gt;%
  rename(PC1 = PC1, PC2 = PC2) %&gt;%
  bind_cols(df %&gt;% select(context))
```

![](11_01_week_files/figure-html/unnamed-chunk-22-1.png)&lt;!-- --&gt;

---

# What success looks like

- You use scatterplots to describe:
  - direction, strength, form, and exceptions
- You can explain **mapping vs styling** in `ggplot2`
- You treat correlation as a *summary*, not a substitute for a plot
- You can choose Pearson vs rank-based correlation intentionally
- You can read correlograms as “where to look next,” not “final answers”
- You can recognize paired data and choose a paired visualization

---



# In-Class Activity

Find a visualization online.

With a neighbor:
- Identify the data variables
- Identify the visual mappings
- Decide what message the plot is making
- Suggest one concrete improvement


---

# What Comes Next

Next, we will move from “make a scatterplot” to an **interpretation-first workflow**:

- start with a question
- choose a minimal plot that answers it
- add layers only when they clarify the argument
- practice correlation heatmaps and small multiples
- (optional) treat PCA as a geometric summary, not a black box
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
  "highlightStyle": "github",
  "highlightLines": true,
  "countIncrementalSlides": false,
  "slideNumberFormat": ""
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
// add `data-at-shortcutkeys` attribute to <body> to resolve conflicts with JAWS
// screen reader (see PR #262)
(function(d) {
  let res = {};
  d.querySelectorAll('.remark-help-content table tr').forEach(tr => {
    const t = tr.querySelector('td:nth-child(2)').innerText;
    tr.querySelectorAll('td:first-child .key').forEach(key => {
      const k = key.innerText;
      if (/^[a-z]$/.test(k)) res[k] = t;  // must be a single letter (key)
    });
  });
  d.body.setAttribute('data-at-shortcutkeys', JSON.stringify(res));
})(document);
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>

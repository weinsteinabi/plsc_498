---
title: "Coding Assignment: Associations Among Quantitative Variables"
subtitle: "A quick recap + starter patterns you will extend (scatterplots, smoothers, correlation)"
author: "Jared Edgerton"
output:
  xaringan::moon_reader:
    css: [default, metropolis, metropolis-fonts, plsc498.css]
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
      slideNumberFormat: ""
---


# Today

We are practicing **association** questions:

- Start with a **scatterplot** (show the points)
- Use **alpha** when plots get dense
- Add a **smoother** to summarize pattern (and say what it assumes)
- Use **small multiples** when a third variable would clutter a single panel
- Use **correlation** as a compact summary *after* you’ve looked at points
- For curved patterns: consider **polynomials** (low degree) and show uncertainty with **standard errors**

Goal: you will reuse these starter patterns for your own “two variables + interpretation” workflow.

---

# Setup

```{r, message=FALSE, warning=FALSE}
library(tidyverse)
library(ggplot2)
library(scales)
library(forcats)

set.seed(123)
```

---

# Simulated data for today (setup)

```{r, message=FALSE, warning=FALSE}
df <- tibble(
  id = 1:1800,
  context = sample(
    c("Urban", "Suburban", "Rural"),
    size = 1800,
    replace = TRUE,
    prob = c(0.45, 0.35, 0.20)
  ),
  age = round(rnorm(1800, mean = 40, sd = 12))
) %>%
  mutate(
    context = factor(context, levels = c("Urban", "Suburban", "Rural")),
    age = pmin(pmax(age, 18), 75),
    news = rbeta(1800, 2, 2) * 10 +
      case_when(
        context == "Urban" ~ 0.8,
        context == "Rural" ~ -0.7,
        TRUE ~ 0
      ) +
      rnorm(1800, 0, 0.6),
    news = pmin(pmax(news, 0), 10)
  )
```

---

# Simulated data main outcomes

```{r, message=FALSE, warning=FALSE}
df <- df %>%
  mutate(
    knowledge = 40 + 4.2 * news + 0.35 * (age - 40) + rnorm(1800, 0, 8),
    knowledge = pmin(pmax(knowledge, 0), 100),
    trust = 4.4 + 0.02 * knowledge - 0.10 * news +
      case_when(context == "Rural" ~ 0.2, TRUE ~ 0) +
      rnorm(1800, 0, 0.6),
    trust = pmin(pmax(trust, 1), 7),
    support = 50 + 0.55 * knowledge - 0.40 * (age - 40) +
      case_when(context == "Rural" ~ -4, TRUE ~ 0) +
      rnorm(1800, 0, 10),
    support = pmin(pmax(support, 0), 100)
  )
```

---

# Simulated data tails

```{r, message=FALSE, warning=FALSE}
df <- df %>%
  mutate(
    donation = exp(news / 2) * 15 + rlnorm(1800, meanlog = 0, sdlog = 0.25),
    log_donation = log(donation),
    polarization = 12 + 2.2 * (news - 5)^2 + rnorm(1800, 0, 1.8),
    polarization = pmin(pmax(polarization, 0), 45),
    trust_t1 = pmin(pmax(trust + rnorm(1800, 0, 0.4), 1), 7),
    trust_t2 = pmin(pmax(
      trust_t1 +
        0.25 * (context == "Urban") - 0.20 * (context == "Rural") +
        rnorm(1800, 0, 0.35),
      1
    ), 7)
  ) %>%
  select(
    id, context, age, news, knowledge, trust, support,
    donation, log_donation, polarization, trust_t1, trust_t2
  )
```

---

# Quick check

```{r, message=FALSE, warning=FALSE}
df %>%
  summarise(
    n = n(),
    news_min = min(news),
    news_median = median(news),
    news_max = max(news),
    donation_median = median(donation),
    donation_max = max(donation)
  )
```

---

# Starter pattern: scatterplot

```{r, message=FALSE, warning=FALSE, fig.width=7, fig.height=4}
ggplot(df, aes(x = news, y = knowledge, color = context)) +
  geom_point(alpha = 0.30, size = 1.2) +
  theme_classic() +
  theme(legend.position = "bottom") +
  labs(
    x = "News exposure (0–10)",
    y = "Knowledge (0–100)",
    color = "Context",
    title = "Start with points: association + spread"
  )
```

---

# Starter pattern: add a smoother

```{r, message=FALSE, warning=FALSE, fig.width=7, fig.height=4}
ggplot(df, aes(x = news, y = knowledge, color = context)) +
  geom_point(alpha = 0.20, size = 1.1) +
  geom_smooth(se = FALSE, linewidth = 1.0) +
  theme_classic() +
  theme(legend.position = "bottom") +
  labs(
    x = "News exposure (0–10)",
    y = "Knowledge (0–100)",
    color = "Context",
    title = "Smoother = a summarized pattern (be explicit about what it assumes)"
  )
```

---

# Adding standard errors

If you set `se = TRUE`, ggplot draws a ribbon for uncertainty around the smooth. Important: this ribbon is uncertainty about the **estimated mean trend**, not a prediction band for individual points.

```{r, message=FALSE, warning=FALSE, fig.width=7, fig.height=4}
ggplot(df, aes(x = news, y = knowledge)) +
  geom_point(alpha = 0.20, size = 1.1) +
  geom_smooth(se = TRUE, linewidth = 1.0) +
  theme_classic() +
  labs(
    x = "News exposure (0–10)",
    y = "Knowledge (0–100)",
    title = "Standard errors around the smoother (default ribbon)"
  )
```

---

# Styling the standard error ribbon

You can control the ribbon using `fill` and `alpha` inside `geom_smooth()`.

```{r, message=FALSE, warning=FALSE, fig.width=7, fig.height=4}
ggplot(df, aes(x = news, y = knowledge)) +
  geom_point(alpha = 0.20, size = 1.1) +
  geom_smooth(se = TRUE, linewidth = 1.0, fill = "grey70", alpha = 0.35) +
  theme_classic() +
  labs(x = "News exposure (0–10)",
       y = "Knowledge (0–100)",
       title = "Make the ribbon visible but not dominant")
```

---

# Polynomial fits

We built `polarization` to have a curved relationship with `news`. Start with points.

```{r, message=FALSE, warning=FALSE, fig.width=7, fig.height=4}
ggplot(df, aes(x = news, y = polarization, color = context)) +
  geom_point(alpha = 0.30, size = 1.2) +
  theme_classic() +
  theme(legend.position = "bottom") +
  labs(x = "News exposure (0–10)", y = "Polarization index", color = "Context", title = "Curvature is visible in points")
```

---

# Linear vs quadratic (polynomial)

Here are two common formulas: (a) Linear: `y ~ x` and (b) Quadratic: `y ~ poly(x, 2)` (a 2nd-degree polynomial)

```{r, message=FALSE, warning=FALSE, fig.width=7, fig.height=4}
ggplot(df, aes(x = news, y = polarization)) +
  geom_point(alpha = 0.20, size = 1.1) +
  geom_smooth(method = "lm", formula = y ~ x, se = TRUE, linewidth = 1.0) +
  theme_classic() +
  labs(x = "News exposure (0–10)", y = "Polarization index", title = "Linear fit: may miss curvature")
```

---

# Quadratic fit + standard errors

```{r, message=FALSE, warning=FALSE, fig.width=7, fig.height=4}
ggplot(df, aes(x = news, y = polarization)) +
  geom_point(alpha = 0.20, size = 1.1) +
  geom_smooth(method = "lm", formula = y ~ poly(x, 2), se = TRUE, linewidth = 1.0) +
  theme_classic() +
  labs(x = "News exposure (0–10)", y = "Polarization index", title = "Quadratic fit: captures curvature (with uncertainty ribbon)")
```

---

# Polynomial by group (use carefully)

This can work when: (a) each group has enough data, (b) the plot stays readable, (c) your goal is comparing *curves*, not just single slopes

```{r, message=FALSE, warning=FALSE, fig.width=7, fig.height=4}
ggplot(df, aes(x = news, y = polarization, color = context, fill = context)) +
  geom_point(alpha = 0.10, size = 1.0) +
  geom_smooth(method = "lm", formula = y ~ poly(x, 2), se = TRUE, linewidth = 1.0, alpha = 0.20) +
  theme_classic() +
  theme(legend.position = "bottom") +
  labs(
    x = "News exposure (0–10)",
    y = "Polarization index",
    color = "Context",
    fill = "Context",
    title = "Group-wise polynomial smoothers (ribbons can clutter)"
  )
```

---

# Correlation (use after you’ve looked at points)

Pearson correlation summarizes **linear** association.
Spearman summarizes **monotonic** association.

```{r, message=FALSE, warning=FALSE}
cor_summary <- tibble(
  pearson = cor(df$news, df$knowledge, method = "pearson"),
  spearman = cor(df$news, df$knowledge, method = "spearman")
)

cor_summary
```
